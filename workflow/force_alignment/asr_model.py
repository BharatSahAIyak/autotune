import torch
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, AutoTokenizer

class Model:
    """
    A class representing a pre-trained mms 1b model for speech recognition using CTC (Connectionist Temporal Classification).

    Attributes:
        _instance (Model): The singleton instance of the Model class.
        DEVICE (torch.device): The device to use for inference (CUDA if available, otherwise CPU).
        MODEL_ID (str): The identifier for the pre-trained model from Hugging Face Transformers library.

    Methods:
        tokenize(transcript): Tokenizes a given transcript into token IDs.
        prepare_input(audio): Prepares the input audio for inference by processing it using the model's processor.
        inference(audio): Performs inference on the input audio to generate logits using the pre-trained model.
    """

    _instance = None
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    MODEL_ID = "facebook/mms-1b-all"

    def __new__(cls, *args, **kwargs):
        """
        Creates a singleton instance of the Model class and initializes the model, processor, and tokenizer.
        """
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance.model = Wav2Vec2ForCTC.from_pretrained(cls.MODEL_ID).to(cls.DEVICE)
            cls._instance.processor = Wav2Vec2Processor.from_pretrained(cls.MODEL_ID)
            cls._instance.processor.tokenizer.set_target_lang("hin")
            cls._instance.model.load_adapter("hin")
            cls._instance.tokenizer = AutoTokenizer.from_pretrained(cls.MODEL_ID)
            cls._instance.tokenizer.set_target_lang("hin")

        return cls._instance

    def tokenize(self, transcript):
        """
        Tokenizes a given transcript into token IDs.

        Args:
            transcript (str): The input transcript to tokenize.

        Returns:
            token_ids (list): List of token IDs representing the transcript.
        """
        tokens = self.tokenizer.tokenize(transcript)
        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)
        return token_ids

    def prepare_input(self, audio):
        """
        Prepares the input audio for inference by processing it using the model's processor.

        Args:
            audio (torch.Tensor): The input audio waveform.

        Returns:
            input_values (torch.Tensor): Processed input values ready for inference.
        """
        input_values = self.processor(audio, return_tensors="pt").input_values
        input_values = input_values.to(self.DEVICE)
        return input_values

    def inference(self, audio):
        """
        Performs inference on the input audio to generate logits using the pre-trained model.

        Args:
            audio (torch.Tensor): The input audio waveform.

        Returns:
            logits (torch.Tensor): Logits generated by the model for the input audio.
        """
        input_values = self.prepare_input(audio)

        with torch.no_grad():
            logits = self.model(input_values).logits

        emission = logits.cpu().detach()

        return emission[0]